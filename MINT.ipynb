{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":123659,"status":"ok","timestamp":1752734667455,"user":{"displayName":"조시현","userId":"17483893386690202078"},"user_tz":-540},"id":"WPFVLlCCoad0","outputId":"083f6bcc-865f-4df9-8902-9cee39b1eeee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.10)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycocotools) (2.0.2)\n","Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"]}],"source":["!pip install pycocotools torchvision nltk tqdm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yz0pV0C05wS6"},"outputs":[],"source":["from torchvision.datasets import CIFAR10\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset\n","\n","CIFAR10_LABELS = [\n","    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n","    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n","]\n","\n","class CIFAR10WithText(Dataset):\n","    def __init__(self, train=True):\n","        transform = transforms.Compose([\n","            transforms.ToTensor()\n","        ])\n","        self.dataset = CIFAR10(root='./data', train=train, download=True, transform=transform)\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        image, label = self.dataset[idx]\n","        text = CIFAR10_LABELS[label]\n","        return image, text\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vMtHuJc65xQ2"},"outputs":[],"source":["# 큰 모델\n","import torch\n","import torch.nn as nn\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel, BertTokenizer, BertModel\n","import torchvision.models as models\n","\n","class InvertibleBlock(nn.Module):\n","    def __init__(self, dim):\n","        super().__init__()\n","        self.linear = nn.Linear(dim, dim)\n","        self.norm = nn.LayerNorm(dim)\n","        self.act = nn.GELU()\n","\n","    def forward(self, x, reverse=False):\n","        if not reverse:\n","            x = self.linear(x)\n","            x = self.norm(x)\n","            return self.act(x)\n","        else:\n","            W = self.linear.weight\n","            b = self.linear.bias\n","            return torch.linalg.solve(W.T, (x - b).T).T\n","\n","class SharedNetwork(nn.Module):\n","    def __init__(self, dim=768, depth=4):\n","        super().__init__()\n","        self.blocks = nn.ModuleList([InvertibleBlock(dim) for _ in range(depth)])\n","\n","    def forward(self, x, reverse=False):\n","        for block in (reversed(self.blocks) if reverse else self.blocks):\n","            x = block(x, reverse=reverse)\n","        return x\n","\n","class ConvDecoder(nn.Module):\n","    def __init__(self, dim=768):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(dim, 512 * 7 * 7),\n","            nn.ReLU(),\n","            nn.Unflatten(1, (512, 7, 7)),\n","            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),  # 7 -> 14\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),  # 14 -> 28\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),   # 28 -> 56\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),    # 56 -> 112\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1),     # 112 -> 224\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","\n","\n","class BiModalModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.image_encoder = models.resnet18(weights='DEFAULT')\n","        self.image_encoder.fc = nn.Linear(512, 768)\n","\n","        self.text_encoder = BertModel.from_pretrained(\"bert-base-uncased\")\n","        self.text_decoder = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","\n","        self.shared = SharedNetwork(dim=768)\n","        self.img_proj = nn.Linear(768, 768)\n","        self.txt_proj = nn.Linear(768, 768)\n","        self.image_decoder = ConvDecoder()\n","\n","    def forward_image_to_text(self, image):\n","        img_feat = self.image_encoder(image)  # (B, 768)\n","        z = self.shared(img_feat, reverse=False)\n","        gpt_input = self.img_proj(z).unsqueeze(1)\n","        out = self.text_decoder(inputs_embeds=gpt_input)\n","        return out\n","\n","    def forward_text_to_image(self, input_ids, attention_mask):\n","        txt_feat = self.text_encoder(input_ids, attention_mask).last_hidden_state[:, 0]  # CLS\n","        z = self.shared(txt_feat, reverse=True)\n","        return self.image_decoder(z)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6wLJpDprKJ89"},"outputs":[],"source":["# 개선된 작은 버전\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","from transformers import DistilBertModel, DistilBertTokenizer, GPT2LMHeadModel, GPT2Tokenizer\n","\n","# InvertibleBlock 및 SharedNetwork (더 크게)\n","class InvertibleBlock(nn.Module):\n","    def __init__(self, dim):\n","        super().__init__()\n","        self.linear = nn.Linear(dim, dim)\n","        self.norm = nn.LayerNorm(dim)\n","        self.act = nn.GELU()\n","\n","    def forward(self, x, reverse=False):\n","        if not reverse:\n","            return self.act(self.norm(self.linear(x)))\n","        else:\n","            W = self.linear.weight\n","            b = self.linear.bias\n","            return torch.linalg.solve(W.T, (x - b).T).T\n","\n","class SharedNetwork(nn.Module):\n","    def __init__(self, dim=2048, depth=6):\n","        super().__init__()\n","        self.blocks = nn.ModuleList([InvertibleBlock(dim) for _ in range(depth)])\n","\n","    def forward(self, x, reverse=False):\n","        for block in (reversed(self.blocks) if reverse else self.blocks):\n","            x = block(x, reverse=reverse)\n","        return x\n","\n","# 간단한 Image Encoder (작게)\n","class SimpleImageEncoder(nn.Module):\n","    def __init__(self, output_dim=512):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Conv2d(3, 32, 3, 2, 1),  # 32x16x16\n","            nn.ReLU(),\n","            nn.Conv2d(32, 64, 3, 2, 1),  # 64x8x8\n","            nn.ReLU(),\n","            nn.AdaptiveAvgPool2d((1, 1)),\n","            nn.Flatten(),\n","            nn.Linear(64, output_dim)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","# 간단한 ConvDecoder\n","class ConvDecoder(nn.Module):\n","    def __init__(self, dim=2048):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(dim, 256 * 4 * 4),\n","            nn.ReLU(),\n","            nn.Unflatten(1, (256, 4, 4)),\n","            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),  # 8x8\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),  # 16x16\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),  # 32x32\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class BiModalModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # self.image_encoder = SimpleImageEncoder(output_dim=512)\n","        self.image_encoder = models.resnet18(weights='DEFAULT')\n","        self.image_encoder.fc = nn.Linear(512, 512)\n","        self.text_encoder = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n","        self.text_decoder = GPT2LMHeadModel.from_pretrained(\"distilgpt2\")\n","\n","        # projection to shared space (dim=2048)\n","        self.to_shared_img = nn.Linear(512, 2048)\n","        self.to_shared_txt = nn.Linear(768, 2048)\n","\n","        self.shared = SharedNetwork(dim=2048, depth=6)\n","\n","        self.to_gpt_embed = nn.Linear(2048, self.text_decoder.config.n_embd)\n","        self.image_decoder = ConvDecoder(dim=2048)\n","\n","    def forward_image_to_text(self, image):\n","        img_feat = self.image_encoder(image)              # (B, 512)\n","        shared = self.shared(self.to_shared_img(img_feat), reverse=False)\n","        gpt_input = self.to_gpt_embed(shared).unsqueeze(1)\n","        return self.text_decoder(inputs_embeds=gpt_input)\n","\n","    def forward_text_to_image(self, input_ids, attention_mask):\n","        txt_feat = self.text_encoder(input_ids, attention_mask).last_hidden_state[:, 0]\n","        shared = self.shared(self.to_shared_txt(txt_feat), reverse=True)\n","        return self.image_decoder(shared)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"JPdkj-ip5ye8","outputId":"994dc1d0-35c0-4d68-9eb9-65a83aad1311"},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1:  38%|███▊      | 1189/3125 [1:29:50<2:51:34,  5.32s/it, loss=1.6546, loss1=1.3550, loss2=0.2996, acc=41.93%]"]}],"source":["\n","import torch\n","import torch.nn.functional as F\n","from transformers import BertTokenizer, GPT2Tokenizer\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 토크나이저 로드\n","bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","gpt_tokenizer.pad_token = gpt_tokenizer.eos_token  # pad_token 세팅\n","\n","# 모델 초기화\n","model = BiModalModel().to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n","\n","# 데이터셋 및 로더\n","dataset = CIFAR10WithText(train=True)\n","loader = DataLoader(dataset, batch_size=16, shuffle=True)\n","\n","os.makedirs(\"checkpoints\", exist_ok=True)  # 저장 폴더 만들기\n","\n","best_loss = float(\"inf\")\n","best_acc = 0.0\n","\n","model.train()\n","for epoch in range(5):\n","    total_correct = 0\n","    total_tokens = 0\n","    total_loss = 0.0\n","\n","    pbar = tqdm(loader, desc=f\"Epoch {epoch+1}\")\n","    for images, texts in pbar:\n","        images = images.to(device)\n","\n","        # 1) 이미지 → 텍스트\n","        gpt_enc = gpt_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n","        input_ids = gpt_enc.input_ids.to(device)\n","        attention_mask = gpt_enc.attention_mask.to(device)\n","\n","        out = model.forward_image_to_text(images)\n","        logits = out.logits\n","        min_len = min(logits.size(1), input_ids.size(1))\n","\n","        # 손실 계산\n","        loss1 = F.cross_entropy(\n","            logits[:, :min_len, :].reshape(-1, logits.size(-1)),\n","            input_ids[:, :min_len].reshape(-1),\n","            ignore_index=gpt_tokenizer.pad_token_id\n","        )\n","\n","        # 정확도 계산\n","        preds = torch.argmax(logits[:, :min_len, :], dim=-1)\n","        mask = (input_ids[:, :min_len] != gpt_tokenizer.pad_token_id)\n","\n","        correct = (preds == input_ids[:, :min_len]) & mask\n","        total_correct += correct.sum().item()\n","        total_tokens += mask.sum().item()\n","\n","        # 2) 텍스트 → 이미지\n","        bert_enc = bert_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n","        '''\n","        txt_feat = model.text_encoder(input_ids=bert_enc.input_ids, attention_mask=bert_enc.attention_mask).last_hidden_state[:, 0]\n","\n","        shared_feat = model.shared(txt_feat, reverse=True)\n","        recon_img = model.image_decoder(shared_feat)'''\n","\n","        recon_img = model.forward_text_to_image(bert_enc.input_ids, bert_enc.attention_mask)\n","\n","        loss2 = F.mse_loss(recon_img, images)\n","\n","        # 최종 손실\n","        loss = loss1 + loss2\n","        total_loss += loss.item()\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # tqdm 출력 업데이트\n","        acc = total_correct / total_tokens * 100 if total_tokens > 0 else 0\n","        pbar.set_postfix({\n","            'loss': f\"{loss.item():.4f}\",\n","            'loss1': f\"{loss1.item():.4f}\",\n","            'loss2': f\"{loss2.item():.4f}\",\n","            'acc': f\"{acc:.2f}%\"\n","        })\n","\n","    # 🔽 체크포인트 저장\n","    avg_loss = total_loss / len(loader)\n","    final_acc = total_correct / total_tokens * 100\n","\n","    if avg_loss < best_loss:\n","        best_loss = avg_loss\n","        torch.save(model.state_dict(), \"checkpoints/best_loss.pt\")\n","\n","    if final_acc > best_acc:\n","        best_acc = final_acc\n","        torch.save(model.state_dict(), \"checkpoints/best_acc.pt\")\n","\n","    torch.save(model.state_dict(), \"checkpoints/last.pt\")\n","    print(f\"[Epoch {epoch+1}] Loss: {avg_loss:.4f} | Text Accuracy: {final_acc:.2f}%\")\n"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyPpZh/L72HhQLfsbfuJaxSY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}